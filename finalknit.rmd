---
title: "Regression Model Final Project"
author: "Matthew Green"
date: "May 17, 2016"
output: html_document
---

```{r, echo=FALSE, warning=FALSE}
library(ggplot2)
library(gridExtra)
library(data.table)
```

# Exectutive Summary

This analysis is for the Regression Models class on Coursera that is part of the Johns Hopkins University specialization in Data Science. We'll be looking at the `mtcars` dataset and exploring the relationship between a set of variables (predictors) and miles per gallon `mpg` (outcome).  

__The purpose of this report is to answer two questions:__  
  
* Is an automatic or manual transmission better for mpg?  
* Can the difference between automatic and manual transmissions by quantified?  

__Key Findings:__  
  
* Manual transmissions are better for mpg when adjusted for all meaningful variables.  
* There is a __2.94 mpg increase__ in when using a __manual__ transmission instead of an automatic when all other variables are held constant.

# Data Analysis
To begin, let's create a linear model with `mpg` as the outcome and `am` as the predictor then look at its summary. Since this is the dominant relationship we are examining, we'll get to the other predictors later.

```{r}

data(mtcars)
fitam <- lm(mpg ~ am, mtcars) 
summary(fitam)

```

There is a 7.25 mpg increase when driving with a manual transmission according to this model, but that value seems too high. While the t-value is larger than its significant value, looking at the scatter plot and a boxplot of the data in _Figure 1_ in the appendix, it's easy to see how a binary predictor doesn't fit the criterion for a traditional residual plot.  
More predictors are needed.  
  
For our first model we'll include all 10 predictors v `mpg`. 

```{r, echo=FALSE, warning=FALSE}

data(mtcars)
setcolorder(mtcars, c(1, 6, 9, 7, 4, 3, 2, 5, 8, 10, 11))
fit <- lm(mpg ~ ., mtcars)
summary(fit)

```

The summary of the linear model using all 10 predictors and `mpg` as the outcome, results in a 2.52 `mpg` increase when driving with a manual transmission.  
__The predictors are listed in order of t-value significance.__ 

# Model Selection
As seen in the summary, the predictors with significant t-values are `qsec`, `wt`, `hp`, and `disp`. Let's analyze these four predictors starting with residual plots of the 4 predictors v. `mpg`, with `am` as the data point color scale variable.  
Looking at the _Figure 2_ in the appendix, the `qsec` residual plot clearly has the most randomized pattern so we will use this as our first predictor. 

```{r}

fitq <- lm(mpg ~ am + qsec, mtcars)
summary(fitq)

```

The new `mpg` change when including `qsec` in the `am` model is an 8.82 increase when driving a manual. This is much higher than the 2.52 increase when all other predictors were included. Further analysis is needed.  
  
Let's look at the summary of our new model, and create individual residual plots including weight as a variable in the model since it had the largest initial t-value. This plot will be _Figure 3_ in the appendix.  

```{r  }

fitqw <- lm(mpg ~ am + qsec + wt, mtcars)
summary(fitqw)

```

The residual plot is randomly dispersed, and 2.94 `mpg` increase for manual transmission is more in line with the 2.52 increase obtained when using all predictors. Also, the p-value is very low, meaning we can confidently reject the null hypothesis that these variables do not contribute to the model fit. 
  
Now we'll run a chi-square anova test with models including `hp` and `disp` in order to determine if the variables should be used in the final model.

```{r }

fitqwh <- lm(mpg ~ am + qsec + wt + hp, mtcars)
fitqwd <- lm(mpg ~ am + qsec + wt+ disp, mtcars)
anova(fitam, fitq, fitqw, fitqwh, fitqwd, fit, test="Chisq")

```

The RSS drops significantly until the presence of `hp` and `disp` are included in the model. The p-values also reflect this with `qsec` and `wt` being multiple orders of magnitude smaller than `hp` and `disp`.
We now have enough information to determine that `am`, `qsec`, and `wt` create the best linear model with the fewest predictors.  
  
Let's run a quick check using the step function on the initial fit of the all the predictors v. `mpg` as the outcome and see if it comes to the same conclusion.

```{r, eval=FALSE}

fitbest <- step(fit, direction = 'both')

```

```{r, include=FALSE}

fitbest <- step(fit, direction = 'both')

```

```{r }

summary(fitbest)

```

Looks like we're on the right track!

# Model Diagnostic

An examination of the diagnostic plots of our linear model can help us find any problems hidden within our model which can be seen in _Figure 4_ in the appendix.  
  
  
The `Residual v. Fitted` plot is randomly distributed thus avoiding underfitting. The `Normal Q-Q` plot has point falling closely around the line indicating a normal distribution of the data. The `Scale-Location` plot has a constant width among most of the data point indicating an absence of heterodasticity. The `Residual v, Leverage` plot highlights some point that could have increased leverage and influence on our model. Other points of influences can be seen on the other graphs as well. 

## Influential Points

Checking the `hatvalues` and `dfbetas` for our data points will tell us which point have the most leverage and influence on our model. These most likely will be the outliers on our graphs.

```{r }

leverage <- hatvalues(fitqw)
tail(sort(leverage), 3)

influence <- dfbetas(fitqw)
tail(sort(influence), 3)

```

As predicted the data points with the most leverage and influence match the outliers located on our model diagnostic plots in _FIgure 4_! 

# Statistical Inference

The last piece of analysis to perfrom is two sided t-test on the manual and automatic subsets of `mpg`. The t-test assumes that the subsets are each normally distributed and tests the null hypothesis that they come from the same distribution. By default, this performs a two-sided test with \(\alpha=0.05\) and assuming unequal variances. 

```{r }

t.test(mpg ~ am, mtcars)

```

Observing the resulting p-value we can confidently __reject the null hypothesis__ that the distributions for automatic and manual transmitions are equal.

# Conclusions
After analyzing the dataset, fitting multiple models, and verifying the model's fit we have determined the least number of meaningful predictors needed to provide the the `mpg` increase between manual and automatic transmissions.  
  
* A __2.9358 `mpg` increase__ when using a __manual transmission__.  
* A __1.2259 `mpg` increase__ for every `qsec` increase by 1 sec.
* A __3.9165 `mpg` decrease__ for every 1000 lbs increase in `wt`.  

# Appendix
  
```{r, echo=FALSE, warning=FALSE}

fitam <- lm(mpg ~ am, mtcars)

g1 <- ggplot(mtcars, aes(x = am, y = mpg)) + geom_point() + geom_smooth(method=lm)

g2 <- ggplot(mtcars, aes(x = factor(am), y = mpg, colour=factor(am))) + geom_boxplot() + xlab("am") + scale_colour_discrete(name = "Transmission", breaks = c(0, 1), labels = c("Automatic", "Manual"))

grid.arrange(g1, g2, ncol=1, nrow=2)

```
  
_Figure 1: Scatterplot and Boxplot of am v. mpg_  
  
```{r, echo=FALSE}

fitw <- lm(mpg ~ am + wt, mtcars)
fitq <- lm(mpg ~ am + qsec, mtcars)
fith <- lm(mpg ~ am + hp, mtcars)
fitd <- lm(mpg ~ am + disp, mtcars)

y0 = as.numeric(rep(0,32))

g1 <- ggplot(mtcars, aes(x = wt, y = fitq$residuals, colour = factor(am))) + geom_point() + scale_size(guide = 'none') + geom_line(y=0) + geom_segment(aes(x = mtcars$wt, y=fitq$residuals, xend = mtcars$wt, yend = y0)) + scale_colour_discrete(name = "Trans", breaks = c(0, 1), labels = c("A", "M"))

g2 <- ggplot(mtcars, aes(x = qsec, y = fitw$residuals, colour = factor(am))) + geom_point() + scale_size(guide = 'none') + geom_line(y=0) + geom_segment(aes(x = mtcars$qsec, y=fitw$residuals, xend = mtcars$qsec, yend = y0)) + scale_colour_discrete(name = "Trans", breaks = c(0, 1), labels = c("A", "M"))

g3 <- ggplot(mtcars, aes(x = hp, y = fith$residuals, colour = factor(am))) + geom_point() + scale_size(guide = 'none') + geom_line(y=0) + geom_segment(aes(x = mtcars$hp, y=fith$residuals, xend = mtcars$hp, yend = y0)) + scale_colour_discrete(name = "Trans", breaks = c(0, 1), labels = c("A", "M"))

g4 <- ggplot(mtcars, aes(x = disp, y = fitd$residuals, colour = factor(am))) + geom_point() + scale_size(guide = 'none') + geom_line(y=0) + geom_segment(aes(x = mtcars$disp, y=fitd$residuals, xend = mtcars$disp, yend = y0)) + scale_colour_discrete(name = "Trans", breaks = c(0, 1), labels = c("A", "M"))

grid.arrange(g1, g2, g3, g4, ncol=2, nrow=2)

```
  
_Figure 2: Residual Graphs of wt, qsec, hp, and disp v. mpg_  
  
```{r, echo=FALSE}

fitqw <- lm(mpg ~ am + qsec + wt, mtcars)

y0 = as.numeric(rep(0,32))

g1 <- ggplot(mtcars, aes(x = qsec, y = fitqw$residuals, colour = factor(am))) + geom_point(aes(size=2)) + scale_size(guide = 'none') + geom_line(y=0) + geom_segment(aes(x = mtcars$qsec, y=fitqw$residuals, xend = mtcars$qsec, yend = y0)) + scale_colour_discrete(name = "Transmission", breaks = c(0, 1), labels = c("Automatic", "Manual"))

g1

```
  
_Figure 3: Residual Graph of am + qsec + wt v. mpg_  
  
```{r, echo=FALSE}

par(mfrow=c(2,2))
plot(fitqw)

```
  
_Figure 4 Residual Diagnostic Graphs of am + qsec + wt v. mpg_  
